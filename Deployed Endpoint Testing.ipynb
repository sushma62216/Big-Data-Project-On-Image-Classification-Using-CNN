{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ede47afd-de0b-4cf3-8006-b75af2dc6b60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##1. Environment Variable Setup for Databricks Token\n",
    "The code sets an environment variable DATABRICKS_TOKEN with the provided API token for accessing Databricks services programmatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fcca606-d936-4a44-be9b-1dc9b43d80ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "os.environ['DATABRICKS_TOKEN'] = 'dapi6b30506d24458d1fc6b257959970e55e'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96dd5423-c1bc-4a90-9662-3aeee89d7492",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##2. Image Data Preparation for Model Inference\n",
    "This script provides functions to preprocess single or multiple images for inference. It resizes the images to a target size, normalizes the pixel values, and prepares them for input into a trained model. The preprocess_image function handles individual images, while preprocess_images processes a list of image paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cfc23aa-c875-44dd-a100-172aa47fa02d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_image(image_path, target_size=(128, 128)):\n",
    "    \"\"\"\n",
    "    Preprocess a single image for inference.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file.\n",
    "        target_size (tuple): Target size for the image.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Preprocessed image array with shape (128, 128, 3).\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path).convert(\"RGB\")  # Ensure RGB format\n",
    "    image = image.resize(target_size)  # Resize to target dimensions\n",
    "    image_array = np.array(image) / 255.0  # Normalize pixel values\n",
    "    return np.expand_dims(image_array, axis=0)  # Add batch dimension\n",
    "\n",
    "def preprocess_images(image_paths, target_size=(128, 128)):\n",
    "    \"\"\"\n",
    "    Preprocess multiple images for inference.\n",
    "\n",
    "    Args:\n",
    "        image_paths (list): List of paths to image files.\n",
    "        target_size (tuple): Target size for the images.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A batch of preprocessed image arrays with shape (N, 128, 128, 3).\n",
    "    \"\"\"\n",
    "    preprocessed = [preprocess_image(image_path, target_size).squeeze() for image_path in image_paths]\n",
    "    return np.array(preprocessed)\n",
    "\n",
    "# Example usage\n",
    "test_image_paths = [\"C:/Users/sushm/OneDrive/Desktop/00000049.jpg\"] \n",
    "test_dataset = preprocess_images(test_image_paths)\n",
    "print(test_dataset.shape)  # Should be (N, 128, 128, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a03c352-c87a-4ada-9650-213cbfcae67d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##3. Model Scoring via Databricks API\n",
    "This script defines a function to score a model by sending inference requests to a Databricks API endpoint. It converts the input data into the required format, sends a POST request with authentication, and returns the prediction results from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "801b170c-9101-44d8-b23e-44bb5014e0eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def create_tf_serving_json(data):\n",
    "    return {'inputs': {name: data[name].tolist() for name in data.keys()} if isinstance(data, dict) else data.tolist()}\n",
    "\n",
    "def score_model(dataset):\n",
    "    url = 'https://adb-1939233728040159.19.azuredatabricks.net/serving-endpoints/ImgCls/invocations'\n",
    "    headers = {'Authorization': f'Bearer {os.environ.get(\"DATABRICKS_TOKEN\")}', 'Content-Type': 'application/json'}\n",
    "    ds_dict = {'dataframe_split': dataset.to_dict(orient='split')} if isinstance(dataset, pd.DataFrame) else create_tf_serving_json(dataset)\n",
    "    data_json = json.dumps(ds_dict, allow_nan=True)\n",
    "    response = requests.request(method='POST', headers=headers, url=url, data=data_json)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f'Request failed with status {response.status_code}, {response.text}')\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b32b19f-fae2-4020-83c6-e61564532258",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: {'predictions': [[0.11000793427228928, 0.025032397359609604, 0.26926007866859436, 0.050344862043857574, 0.10608160495758057, 0.020273273810744286, 0.001193435164168477, 0.11616825312376022, 0.14967596530914307, 0.15196216106414795]]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Call the scoring function\n",
    "try:\n",
    "    predictions = score_model(test_dataset)\n",
    "    print(\"Predictions:\", predictions)\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b78d6157-0050-4a58-b7da-60129b60ce5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class_labels = [\n",
    "    \"Fountain\", \"Gas Station\", \"Glacier\", \"Hayfield\", \n",
    "    \"Iceberg\", \"Igloo\", \"Lawn\", \"Palace\", \"Runway\", \"Skyscraper\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a162ef3d-60aa-4d3c-b429-aeeab33fbe6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##4. Label Prediction from Model Output\n",
    "This script identifies and prints the predicted label for an image based on the highest prediction score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ba096f1-35ba-4928-88c4-dabfedaaf765",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: Fountain\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming predictions is a numpy array with prediction scores\n",
    "highest_prediction_index = np.argmax(predictions)\n",
    "highest_prediction_label = class_labels[highest_prediction_index]\n",
    "\n",
    "print(\"Predicted Label:\", highest_prediction_label)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Deployed Endpoint Testing",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
